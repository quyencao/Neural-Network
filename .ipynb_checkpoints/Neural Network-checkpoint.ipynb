{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Parameters Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_parameters(layers_dims):\n",
    "    np.random.seed(10)\n",
    "    L = len(layers_dims)\n",
    "    parameters = {}\n",
    "    \n",
    "    for i in range(1, L):\n",
    "        parameters[\"W\" + str(i)] = np.random.randn(layers_dims[i], layers_dims[i - 1]) * np.square(2 / layers_dims[i - 1])\n",
    "        parameters[\"b\" + str(i)] = np.zeros((layers_dims[i], 1))\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = init_parameters([2, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'W1': array([[ 1.3315865 ,  0.71527897],\n",
       "        [-1.54540029, -0.00838385],\n",
       "        [ 0.62133597, -0.72008556],\n",
       "        [ 0.26551159,  0.10854853]]),\n",
       " 'W2': array([[ 0.00107286, -0.04365005,  0.10825655,  0.30075934]]),\n",
       " 'b1': array([[ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.],\n",
       "        [ 0.]]),\n",
       " 'b2': array([[ 0.]])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Help Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    return X * (X > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(np.array([2, -2, -1, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu_backward(X):\n",
    "    return 1 * (X > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu_backward(np.array([2,3,-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feedforward Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_case_feed_forward():\n",
    "    X = np.array([\n",
    "        [1],\n",
    "        [1]\n",
    "    ])\n",
    "    parameters = init_parameters([2, 4, 1])\n",
    "    \n",
    "    Z1 = np.dot(parameters[\"W1\"], X) + parameters[\"b1\"]\n",
    "    A1 = relu(Z1)\n",
    "    Z2 = np.dot(parameters[\"W2\"], A1) + parameters[\"b2\"]\n",
    "    A2 = relu(Z2)\n",
    "    \n",
    "    return (Z1, A1, Z2, A2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Z1, A1, Z2, A2 = test_case_feed_forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Z1 \\n\" + str(Z1) + \"\\n================\")\n",
    "# print(\"A1 \\n\" + str(A1) + \"\\n================\")\n",
    "# print(\"Z2 \\n\" + str(Z2) + \"\\n================\")\n",
    "# print(\"A2 \\n\" + str(A2) + \"\\n================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feed_forward(X, parameters, activation_functions = []):\n",
    "    L = len(parameters) // 2 + 1\n",
    "    caches = []\n",
    "    curr_A = X\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A = curr_A\n",
    "        W = parameters[\"W\" + str(l)]\n",
    "        b = parameters[\"b\" + str(l)]\n",
    "        Z = np.dot(W, A) + b\n",
    "        \n",
    "        curr_A = relu(Z)\n",
    "        \n",
    "        cache = (W, b, A, Z, curr_A)\n",
    "        caches.append(cache)\n",
    "    return curr_A, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AL, caches = feed_forward(np.array([[1],[1]]), parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert(np.array_equal(caches[0][0], parameters[\"W1\"]))\n",
    "# assert(np.array_equal(caches[0][1], parameters[\"b1\"]))\n",
    "# assert(np.array_equal(caches[0][2], np.array([[1],[1]])))\n",
    "# assert(np.array_equal(caches[0][3], Z1))\n",
    "# assert(np.array_equal(caches[0][4], A1))\n",
    "# assert(np.array_equal(caches[1][0], parameters[\"W2\"]))\n",
    "# assert(np.array_equal(caches[1][1], parameters[\"b2\"]))\n",
    "# assert(np.array_equal(caches[1][2], A1))\n",
    "# assert(np.array_equal(caches[1][3], Z2))\n",
    "# assert(np.array_equal(caches[1][4], A2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_case_back_propagation():\n",
    "    parameters = init_parameters([2, 4, 1])\n",
    "    X = np.array([\n",
    "        [1],\n",
    "        [1]\n",
    "    ])\n",
    "    Y = np.array([\n",
    "        [4]\n",
    "    ])\n",
    "    Z1, A1, Z2, A2 = test_case_feed_forward()\n",
    "    m = X.shape[1]\n",
    "    dA2 = - Y / A2 + (1 - Y) / (1 - A2)\n",
    "    dZ2 = dA2 * relu_backward(A2)\n",
    "    dW2 = 1 / m * np.dot(dZ2, A1.T)\n",
    "    db2 = 1 / m * np.sum(dZ2, axis = 1, keepdims=True)\n",
    "    dZ1 = np.dot(parameters[\"W2\"].T, dZ2) * relu_backward(A1)\n",
    "    dW1 = 1 / m * np.dot(dZ1, X.T)\n",
    "    db1 = 1 / m * np.sum(dZ1, axis = 1, keepdims=True)\n",
    "    \n",
    "    grads = {}\n",
    "    grads[\"dW1\"] = dW1\n",
    "    grads[\"dW2\"] = dW2\n",
    "    grads[\"db1\"] = db1\n",
    "    grads[\"db2\"] = db2\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grads = test_case_back_propagation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check(X, Y, parameters, grads, epsilon = 1e-7):\n",
    "    L = len(parameters) // 2 + 1\n",
    "    \n",
    "    number_parameters = get_number_parameters(parameters)\n",
    "    \n",
    "    vector = parameters_to_vector(parameters)\n",
    "    \n",
    "    \n",
    "    gradapprox = np.zeros((number_parameters, 1))\n",
    "    \n",
    "    for i in range(number_parameters):\n",
    "        vector_plus = np.copy(vector)\n",
    "        vector_plus[i][0] += epsilon\n",
    "        cost_plus = compute_cost(X, Y, vector_to_parameters(vector_plus, parameters))\n",
    "        \n",
    "        vector_minus = np.copy(vector)\n",
    "        vector_minus[i][0] -= epsilon\n",
    "        cost_minus = compute_cost(X, Y, vector_to_parameters(vector_minus, parameters))\n",
    "        \n",
    "        d = (cost_plus - cost_minus) / (2 * epsilon)\n",
    "        \n",
    "        gradapprox[i][0] = d\n",
    "    \n",
    "    grad = grads_to_vector(grads)\n",
    "    \n",
    "    numerator = np.linalg.norm(grad - gradapprox)                              \n",
    "    denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)\n",
    "    difference = numerator / denominator\n",
    "    \n",
    "    if difference > 1e-6:\n",
    "        print (\"\\033[93m\" + \"There is a mistake in the backward propagation! difference = \" + str(difference) + \"\\033[0m\")\n",
    "    else:\n",
    "        print (\"\\033[92m\" + \"Your backward propagation works perfectly fine! difference = \" + str(difference) + \"\\033[0m\")\n",
    "    \n",
    "    return difference, vector_to_grads(gradapprox, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_number_parameters(parameters):\n",
    "    L = len(parameters) // 2 + 1\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for i in range(1, L):\n",
    "        W = parameters[\"W\" + str(i)]\n",
    "        b = parameters[\"b\" + str(i)]\n",
    "        \n",
    "        count += W.shape[0] * W.shape[1] + b.shape[0] * b.shape[1]\n",
    "        \n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameters_to_vector(parameters):\n",
    "    L = len(parameters) // 2 + 1\n",
    "    \n",
    "    W = parameters[\"W1\"]\n",
    "    b = parameters[\"b1\"]\n",
    "        \n",
    "    W = W.reshape(W.shape[0] * W.shape[1], 1)\n",
    "    \n",
    "    vector = np.concatenate((W, b), axis = 0)\n",
    "    \n",
    "    for i in range(2, L):\n",
    "        W = parameters[\"W\" + str(i)]\n",
    "        b = parameters[\"b\" + str(i)]\n",
    "        \n",
    "        W = W.reshape(W.shape[0] * W.shape[1], 1)\n",
    "        \n",
    "        curr = np.concatenate((W, b), axis = 0)\n",
    "\n",
    "        vector = np.concatenate((vector, curr), axis = 0)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector = parameters_to_vector(parameters)\n",
    "# assert(vector.shape[0] == 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vector_to_parameters(vector, parameters):\n",
    "    \n",
    "    L = len(parameters) // 2 + 1\n",
    "    \n",
    "    for i in range(1, L):\n",
    "        W = parameters[\"W\" + str(i)]\n",
    "        b = parameters[\"b\" + str(i)]\n",
    "        \n",
    "        num_para_W = W.shape[0] * W.shape[1]\n",
    "        num_para_b = b.shape[0] * b.shape[1]\n",
    "        \n",
    "        vector_W = vector[:num_para_W, :]\n",
    "        vector_b = vector[num_para_W:num_para_W+num_para_b, :]\n",
    "        \n",
    "        vector = vector[num_para_W + num_para_b:, :]\n",
    "        \n",
    "        parameters[\"W\" + str(i)] = vector_W.reshape(W.shape[0], W.shape[1])\n",
    "        parameters[\"b\" + str(i)] = vector_b.reshape(b.shape[0], b.shape[1])\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = vector_to_parameters(vector, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(parameters[\"W1\"].shape == (4, 2))\n",
    "assert(parameters[\"b1\"].shape == (4, 1))\n",
    "assert(parameters[\"W2\"].shape == (1, 4))\n",
    "assert(parameters[\"b2\"].shape == (1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grads_to_vector(parameters):\n",
    "    L = len(parameters) // 2 + 1\n",
    "\n",
    "    W = parameters[\"dW1\"]\n",
    "    b = parameters[\"db1\"]\n",
    "        \n",
    "    W = W.reshape(W.shape[0] * W.shape[1], 1)\n",
    "    \n",
    "    vector = np.concatenate((W, b), axis = 0)\n",
    "    \n",
    "    for i in range(2, L):\n",
    "        W = parameters[\"dW\" + str(i)]\n",
    "        b = parameters[\"db\" + str(i)]\n",
    "        \n",
    "        W = W.reshape(W.shape[0] * W.shape[1], 1)\n",
    "        \n",
    "        curr = np.concatenate((W, b), axis = 0)\n",
    "\n",
    "        vector = np.concatenate((vector, curr), axis = 0)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vector_to_grads(vector, grads):\n",
    "    \n",
    "    L = len(parameters) // 2 + 1\n",
    "    \n",
    "    for i in range(1, L):\n",
    "        dW = grads[\"dW\" + str(i)]\n",
    "        db = grads[\"db\" + str(i)]\n",
    "        \n",
    "        num_para_dW = dW.shape[0] * dW.shape[1]\n",
    "        num_para_db = db.shape[0] * db.shape[1]\n",
    "        \n",
    "        vector_dW = vector[:num_para_dW, :]\n",
    "        vector_db = vector[num_para_dW:num_para_dW+num_para_db, :]\n",
    "        \n",
    "        vector = vector[num_para_dW + num_para_db:, :]\n",
    "        \n",
    "        grads[\"dW\" + str(i)] = vector_dW.reshape(dW.shape[0], dW.shape[1])\n",
    "        grads[\"db\" + str(i)] = vector_db.reshape(db.shape[0], db.shape[1])\n",
    "        \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(X, Y, parameters):\n",
    "    A, caches = feed_forward(X, parameters)\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    cost = 1. / m * np.sum(-Y * np.log(A) - (1 - Y) * np.log(1 - A))\n",
    "\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diff, gradaprox = gradient_check(np.array([[1], [1]]), np.array([[4]]), parameters, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradaprox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def back_propagation(AL, Y, caches):\n",
    "    m = AL.shape[1]\n",
    "    L = len(caches)\n",
    "    \n",
    "    grads = {}\n",
    "    prev_dA = {}\n",
    "    \n",
    "    W, b, prev_A, Z, curr_A = caches[L - 1]  \n",
    "    dAL = -Y / AL + (1 - Y) / (1 - AL)\n",
    "    dZL = dAL * relu_backward(curr_A)\n",
    "    \n",
    "    grads[\"dW\" + str(L)] = 1.0 / m * np.dot(dZL, prev_A.T)\n",
    "    grads[\"db\" + str(L)] = 1.0 / m * np.sum(dZL, axis = 1, keepdims=True)\n",
    "    prev_dA[\"dA\" + str(L - 1)] = np.dot(W.T, dZL)\n",
    "    \n",
    "    for l in reversed(range(1, L)):\n",
    "        W, b, prev_A, Z, curr_A = caches[l - 1]\n",
    "        dA = prev_dA[\"dA\" + str(l)]\n",
    "\n",
    "        dZ = dA * relu_backward(curr_A)\n",
    "        \n",
    "        grads[\"dW\" + str(l)] = 1.0 / m * np.dot(dZ, prev_A.T)\n",
    "        grads[\"db\" + str(l)] = 1.0 / m * np.sum(dZ, axis = 1, keepdims=True)\n",
    "        prev_dA[\"dA\" + str(l - 1)] = np.dot(W.T, dZ)\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = init_parameters([2, 4, 4, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "AL, caches = feed_forward(np.array([[1], [1]]), parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "grads = back_propagation(AL, np.array([[4]]), caches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mYour backward propagation works perfectly fine! difference = 7.46786042651e-11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "diff, grad_aprox = gradient_check(np.array([[1], [1]]), np.array([[4]]), parameters, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dW1': array([[ -0.0383493 ,  -0.0383493 ],\n",
       "        [  0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ],\n",
       "        [-10.75064215, -10.75064215]]),\n",
       " 'dW2': array([[-73.16520249,   0.        ,   0.        , -13.37077795],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ]]),\n",
       " 'dW3': array([[-14.59433714,   0.        ,   0.        ,   0.        ]]),\n",
       " 'db1': array([[ -0.0383493 ],\n",
       "        [  0.        ],\n",
       "        [  0.        ],\n",
       "        [-10.75064215]]),\n",
       " 'db2': array([[-35.74499803],\n",
       "        [  0.        ],\n",
       "        [  0.        ],\n",
       "        [  0.        ]]),\n",
       " 'db3': array([[-127.24135004]])}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_aprox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dW1': array([[ -0.0383493 ,  -0.0383493 ],\n",
       "        [  0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ],\n",
       "        [-10.75064215, -10.75064215]]),\n",
       " 'dW2': array([[-73.16520249,   0.        ,   0.        , -13.37077795],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ],\n",
       "        [  0.        ,   0.        ,   0.        ,   0.        ]]),\n",
       " 'dW3': array([[-14.59433714,   0.        ,   0.        ,   0.        ]]),\n",
       " 'db1': array([[ -0.0383493 ],\n",
       "        [  0.        ],\n",
       "        [  0.        ],\n",
       "        [-10.75064215]]),\n",
       " 'db2': array([[-35.74499803],\n",
       "        [  0.        ],\n",
       "        [  0.        ],\n",
       "        [  0.        ]]),\n",
       " 'db3': array([[-127.24135004]])}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
